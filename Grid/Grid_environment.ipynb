{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "State Space:  (25, 5, 5)\n",
      "Terminal State Co-ordinates [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 2), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (4, 4)]\n",
      "[[50. -1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1. -1.]]\n",
      "[[-1. 50. -1. -1. -1.]\n",
      " [-1. -1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1. -1.]]\n",
      "[[-1. -1. 50. -1. -1.]\n",
      " [-1. -1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1. -1.]]\n",
      "[[-1. -1. -1. 50. -1.]\n",
      " [-1. -1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1. -1.]]\n",
      "[[-1. -1. -1. -1. 50.]\n",
      " [-1. -1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1. -1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pygame\n",
    "\n",
    "env_y = 5\n",
    "env_x = 5\n",
    "env_z = env_y * env_x\n",
    "env_state_space = np.ones((env_z, env_y, env_x))\n",
    "env_state_space = np.negative(env_state_space)\n",
    "print(\"State Space: \", env_state_space.shape)\n",
    "\n",
    "y_bound = env_y - 1\n",
    "x_bound = env_x - 1\n",
    "\n",
    "env_term_state = list()\n",
    "for y in range(env_y):\n",
    "    for x in range(env_x):\n",
    "        env_term_state.append((y,x))\n",
    "        \n",
    "\n",
    "print(\"Terminal State Co-ordinates\", env_term_state)\n",
    "\n",
    "for state in range(env_z):\n",
    "    env_state_space[state][env_term_state[state]] = 50\n",
    "\n",
    "\n",
    "for iter in range(5):\n",
    "    print(env_state_space[iter])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movement Code of the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move(state,action):\n",
    "    # (y,x)\n",
    "    \n",
    "    switch = {\n",
    "        0: up,\n",
    "        1: right,\n",
    "        2: down,\n",
    "        3: left,\n",
    "        4: pickup\n",
    "    }\n",
    "\n",
    "    func = switch.get(action, lambda: \"Invalid action\")\n",
    "    new_state = func(state)\n",
    "    return new_state\n",
    "\n",
    "def valid_move(state):\n",
    "    if state[0] > y_bound:\n",
    "        state = (state[0]-1, state[1])\n",
    "    elif state[0] < 0:\n",
    "        state = (state[0]+1, state[1])\n",
    "        \n",
    "    if state[1] > x_bound:\n",
    "        state = (state[0], state[1] - 1)\n",
    "    elif state[1] < 0:\n",
    "        state = (state[0], state[1] + 1)\n",
    "    \n",
    "    return state\n",
    "    \n",
    "def up(state):\n",
    "    new_state = (state[0] - 1, state[1])\n",
    "    new_state = valid_move(new_state)\n",
    "    return new_state\n",
    "\n",
    "def right(state):\n",
    "    new_state = (state[0], state[1] + 1)\n",
    "    new_state = valid_move(new_state)\n",
    "    return new_state\n",
    "    \n",
    "def down(state):\n",
    "    new_state = (state[0] + 1, state[1])\n",
    "    new_state = valid_move(new_state)\n",
    "    return new_state\n",
    "    \n",
    "def left(state):\n",
    "    new_state = (state[0], state[1] - 1)\n",
    "    new_state = valid_move(new_state)\n",
    "    return new_state\n",
    "    \n",
    "def pickup(state):\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual transition of the environment based on action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(state, action, terminal_state):\n",
    "    \n",
    "    state_prime = move(state,action)\n",
    "    reward = env_state_space[(terminal_state, state_prime[0], state_prime[1])]\n",
    "    \n",
    "    #insert compare to grand dictionary of terminal states\n",
    "    \n",
    "    if state_prime == env_term_state[terminal_state]:\n",
    "        done = True\n",
    "    else:\n",
    "        done = False\n",
    "    \n",
    "    return state_prime, reward, done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best action selection function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_action_value(state,terminal_state):\n",
    "    best_action = None\n",
    "    best_value  = float('-inf')\n",
    "\n",
    "    for action in ACTION_SPACE:\n",
    "        state_prime, reward, done = step(state, action,terminal_state) \n",
    "        v = reward + gamma * V[terminal_state, state_prime[0], state_prime[1]] \n",
    "        \n",
    "        if v > best_value:\n",
    "            best_value = v\n",
    "            best_action = action\n",
    "    return best_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Space:\n",
      "[0, 1, 2, 3]\n",
      "['Up', 'Right', 'Down', 'Left']\n",
      "V -  (25, 5, 5)\n",
      "Pi -  (25, 5, 5)\n",
      "[[-1. -1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1. 50.]]\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "ACTION_SPACE = list(range(0,4))\n",
    "\n",
    "print(\"Action Space:\")\n",
    "print(ACTION_SPACE)\n",
    "print([\"Up\", \"Right\", \"Down\", \"Left\"])\n",
    "\n",
    "Reward = env_state_space\n",
    "V = np.zeros((env_z, env_y, env_x)) \n",
    "Pi = np.zeros((env_z, env_y, env_x))  \n",
    "\n",
    "print(\"V - \", V.shape)\n",
    "print(\"Pi - \", Pi.shape)\n",
    "print(Reward[24])\n",
    "\n",
    "print(V[24])\n",
    "print(Pi[24])\n",
    "\n",
    "\n",
    "gamma = 0.9 \n",
    "significant_improvement = 0.01 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 3. 3. 3. 3.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "[[1. 0. 3. 3. 3.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "[[1. 1. 0. 3. 3.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "[[1. 1. 1. 0. 3.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "[[1. 1. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "[[2. 2. 2. 2. 2.]\n",
      " [3. 3. 3. 3. 3.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "[[1. 2. 2. 2. 2.]\n",
      " [1. 0. 3. 3. 3.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "[[1. 1. 2. 2. 2.]\n",
      " [1. 1. 0. 3. 3.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "[[1. 1. 1. 2. 2.]\n",
      " [1. 1. 1. 0. 3.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "[[1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "[[2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2.]\n",
      " [3. 3. 3. 3. 3.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "[[1. 2. 2. 2. 2.]\n",
      " [1. 2. 2. 2. 2.]\n",
      " [1. 0. 3. 3. 3.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "[[1. 1. 2. 2. 2.]\n",
      " [1. 1. 2. 2. 2.]\n",
      " [1. 1. 0. 3. 3.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "[[1. 1. 1. 2. 2.]\n",
      " [1. 1. 1. 2. 2.]\n",
      " [1. 1. 1. 0. 3.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "[[1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "[[2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2.]\n",
      " [3. 3. 3. 3. 3.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "[[1. 2. 2. 2. 2.]\n",
      " [1. 2. 2. 2. 2.]\n",
      " [1. 2. 2. 2. 2.]\n",
      " [1. 0. 3. 3. 3.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "[[1. 1. 2. 2. 2.]\n",
      " [1. 1. 2. 2. 2.]\n",
      " [1. 1. 2. 2. 2.]\n",
      " [1. 1. 0. 3. 3.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "[[1. 1. 1. 2. 2.]\n",
      " [1. 1. 1. 2. 2.]\n",
      " [1. 1. 1. 2. 2.]\n",
      " [1. 1. 1. 0. 3.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "[[1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "[[2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2.]\n",
      " [2. 3. 3. 3. 3.]]\n",
      "[[1. 2. 2. 2. 2.]\n",
      " [1. 2. 2. 2. 2.]\n",
      " [1. 2. 2. 2. 2.]\n",
      " [1. 2. 2. 2. 2.]\n",
      " [1. 2. 3. 3. 3.]]\n",
      "[[1. 1. 2. 2. 2.]\n",
      " [1. 1. 2. 2. 2.]\n",
      " [1. 1. 2. 2. 2.]\n",
      " [1. 1. 2. 2. 2.]\n",
      " [1. 1. 2. 3. 3.]]\n",
      "[[1. 1. 1. 2. 2.]\n",
      " [1. 1. 1. 2. 2.]\n",
      " [1. 1. 1. 2. 2.]\n",
      " [1. 1. 1. 2. 2.]\n",
      " [1. 1. 1. 2. 3.]]\n",
      "[[1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 2.]\n",
      " [1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#for one slice of state space\n",
    "for iteration in range(20):\n",
    "    for z in range(env_z):\n",
    "        for y in range(env_y):\n",
    "            for x in range(env_x):\n",
    "                s = (y, x)\n",
    "                action = best_action_value(s,z)\n",
    "                s_new, rew, done = step(s,action,z) \n",
    "                V[z,s[0],s[1]] = rew + gamma * V[(z,s_new[0],s_new[1])] \n",
    "                Pi[z,s[0], s[1]] = action\n",
    "#print(V[24])\n",
    "#print(Pi[24])\n",
    "\n",
    "for iter in range(25):\n",
    "    print(Pi[iter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting position:  (2, 4)\n",
      "Terminal State:  (3, 1)\n",
      "2.0\n",
      "(3, 4)\n",
      "Reward:  -1.0\n",
      "3.0\n",
      "(3, 3)\n",
      "Reward:  -2.0\n",
      "3.0\n",
      "(3, 2)\n",
      "Reward:  -3.0\n",
      "3.0\n",
      "(3, 1)\n",
      "Reward:  47.0\n",
      "Ending position:  (3, 1)\n"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "reward_total = 0\n",
    "iteration = 0\n",
    "\n",
    "start_y = np.random.randint(low=0, high=env_y)\n",
    "start_x = np.random.randint(low=0, high=env_x)\n",
    "current_state = (start_y, start_x)\n",
    "\n",
    "term_y = np.random.randint(low=0, high=env_y)\n",
    "term_x = np.random.randint(low=0, high=env_x)\n",
    "terminal_state_grid = (term_y, term_x)\n",
    "\n",
    "\n",
    "BLACK = (0, 0, 0)\n",
    "WHITE = (255, 255, 255)\n",
    "GREEN = (0, 255, 0)\n",
    "RED = (255, 0, 0)\n",
    " \n",
    "pygame.init()\n",
    "\n",
    "CONSTANT_SIZE = 50\n",
    "height = env_state_space.shape[1]\n",
    "width = env_state_space.shape[2]\n",
    "\n",
    "size_y = (CONSTANT_SIZE * height) + height + 1\n",
    "size_x = (CONSTANT_SIZE * width) + width + 1\n",
    "screen_size = (size_y, size_x)\n",
    "\n",
    "screen = pygame.display.set_mode(screen_size)\n",
    "\n",
    "pygame.display.set_caption(\"Badworld\")\n",
    " \n",
    "session = True\n",
    "\n",
    "clock = pygame.time.Clock()\n",
    "\n",
    "print(\"Starting position: \", current_state)\n",
    "print(\"Terminal State: \", terminal_state_grid)\n",
    "\n",
    "z = env_term_state.index(terminal_state_grid)\n",
    "\n",
    "screen.fill(BLACK)\n",
    "    \n",
    "for y in range(height):\n",
    "    for x in range(width):                \n",
    "        if y == current_state[0] and x == current_state[1]:\n",
    "            colour = GREEN\n",
    "        elif env_state_space[z,y,x] == 50:\n",
    "            colour = RED\n",
    "        else:\n",
    "            colour = WHITE\n",
    "            \n",
    "        rect_pos_x = x*(CONSTANT_SIZE+1)+1\n",
    "        rect_pos_y = y*(CONSTANT_SIZE+1)+1\n",
    "        rect = pygame.Rect(rect_pos_x, rect_pos_y , CONSTANT_SIZE, CONSTANT_SIZE)\n",
    "        pygame.draw.rect(screen, colour, rect) \n",
    "\n",
    "pygame.display.flip()\n",
    "pygame.time.wait(350)    \n",
    "            \n",
    "while session:\n",
    "    \n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            session = False\n",
    " \n",
    "    if done == True:\n",
    "        break\n",
    "\n",
    "    screen.fill(BLACK)\n",
    "    \n",
    "    action = Pi[z,current_state[0],current_state[1]]\n",
    "    print(action)\n",
    "    obs, rew, done = step(current_state, action,z) \n",
    "    print(obs)\n",
    "    current_state = obs\n",
    "    reward_total += rew\n",
    "    \n",
    "    for y in range(height):\n",
    "        for x in range(width):                \n",
    "            if y == current_state[0] and x == current_state[1]:\n",
    "                colour = GREEN\n",
    "            elif env_state_space[z,y,x] == 50:\n",
    "                colour = RED\n",
    "            else:\n",
    "                colour = WHITE\n",
    "            \n",
    "            rect_pos_x = x*(CONSTANT_SIZE+1)+1\n",
    "            rect_pos_y = y*(CONSTANT_SIZE+1)+1\n",
    "            rect = pygame.Rect(rect_pos_x, rect_pos_y , CONSTANT_SIZE, CONSTANT_SIZE)\n",
    "            pygame.draw.rect(screen, colour, rect)    \n",
    "    \n",
    "    print(\"Reward: \" ,reward_total)\n",
    "    \n",
    "    pygame.display.flip()\n",
    "    pygame.time.wait(350)\n",
    "    clock.tick(60)\n",
    "\n",
    "pygame.quit()\n",
    "\n",
    "print(\"Ending position: \", current_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting position:  (0, 2)\n",
      "Terminal State:  (2, 2)\n",
      "2.0\n",
      "(1, 2)\n",
      "Reward:  -1.0\n",
      "2.0\n",
      "(2, 2)\n",
      "Reward:  49.0\n",
      "Ending position:  (2, 2)\n",
      "Starting position:  (2, 1)\n",
      "Terminal State:  (3, 3)\n",
      "1.0\n",
      "(2, 2)\n",
      "Reward:  -1.0\n",
      "1.0\n",
      "(2, 3)\n",
      "Reward:  -2.0\n",
      "2.0\n",
      "(3, 3)\n",
      "Reward:  48.0\n",
      "Ending position:  (3, 3)\n",
      "Starting position:  (0, 4)\n",
      "Terminal State:  (0, 4)\n",
      "0.0\n",
      "(0, 4)\n",
      "Reward:  50.0\n",
      "Ending position:  (0, 4)\n",
      "Starting position:  (3, 4)\n",
      "Terminal State:  (1, 2)\n",
      "0.0\n",
      "(2, 4)\n",
      "Reward:  -1.0\n",
      "0.0\n",
      "(1, 4)\n",
      "Reward:  -2.0\n",
      "3.0\n",
      "(1, 3)\n",
      "Reward:  -3.0\n",
      "3.0\n",
      "(1, 2)\n",
      "Reward:  47.0\n",
      "Ending position:  (1, 2)\n",
      "Starting position:  (1, 4)\n",
      "Terminal State:  (3, 4)\n",
      "2.0\n",
      "(2, 4)\n",
      "Reward:  -1.0\n",
      "2.0\n",
      "(3, 4)\n",
      "Reward:  49.0\n",
      "Ending position:  (3, 4)\n",
      "Starting position:  (2, 2)\n",
      "Terminal State:  (1, 2)\n",
      "0.0\n",
      "(1, 2)\n",
      "Reward:  50.0\n",
      "Ending position:  (1, 2)\n",
      "Starting position:  (4, 3)\n",
      "Terminal State:  (4, 0)\n",
      "3.0\n",
      "(4, 2)\n",
      "Reward:  -1.0\n",
      "3.0\n",
      "(4, 1)\n",
      "Reward:  -2.0\n",
      "3.0\n",
      "(4, 0)\n",
      "Reward:  48.0\n",
      "Ending position:  (4, 0)\n",
      "Starting position:  (4, 0)\n",
      "Terminal State:  (1, 2)\n",
      "0.0\n",
      "(3, 0)\n",
      "Reward:  -1.0\n",
      "0.0\n",
      "(2, 0)\n",
      "Reward:  -2.0\n",
      "0.0\n",
      "(1, 0)\n",
      "Reward:  -3.0\n",
      "1.0\n",
      "(1, 1)\n",
      "Reward:  -4.0\n",
      "1.0\n",
      "(1, 2)\n",
      "Reward:  46.0\n",
      "Ending position:  (1, 2)\n",
      "Starting position:  (0, 3)\n",
      "Terminal State:  (3, 2)\n",
      "2.0\n",
      "(1, 3)\n",
      "Reward:  -1.0\n",
      "2.0\n",
      "(2, 3)\n",
      "Reward:  -2.0\n",
      "2.0\n",
      "(3, 3)\n",
      "Reward:  -3.0\n",
      "3.0\n",
      "(3, 2)\n",
      "Reward:  47.0\n",
      "Ending position:  (3, 2)\n",
      "Starting position:  (3, 1)\n",
      "Terminal State:  (4, 3)\n",
      "1.0\n",
      "(3, 2)\n",
      "Reward:  -1.0\n",
      "1.0\n",
      "(3, 3)\n",
      "Reward:  -2.0\n",
      "2.0\n",
      "(4, 3)\n",
      "Reward:  48.0\n",
      "Ending position:  (4, 3)\n",
      "Starting position:  (4, 1)\n",
      "Terminal State:  (0, 1)\n",
      "0.0\n",
      "(3, 1)\n",
      "Reward:  -1.0\n",
      "0.0\n",
      "(2, 1)\n",
      "Reward:  -2.0\n",
      "0.0\n",
      "(1, 1)\n",
      "Reward:  -3.0\n",
      "0.0\n",
      "(0, 1)\n",
      "Reward:  47.0\n",
      "Ending position:  (0, 1)\n",
      "Starting position:  (2, 3)\n",
      "Terminal State:  (1, 1)\n",
      "0.0\n",
      "(1, 3)\n",
      "Reward:  -1.0\n",
      "3.0\n",
      "(1, 2)\n",
      "Reward:  -2.0\n",
      "3.0\n",
      "(1, 1)\n",
      "Reward:  48.0\n",
      "Ending position:  (1, 1)\n",
      "Starting position:  (3, 4)\n",
      "Terminal State:  (1, 4)\n",
      "0.0\n",
      "(2, 4)\n",
      "Reward:  -1.0\n",
      "0.0\n",
      "(1, 4)\n",
      "Reward:  49.0\n",
      "Ending position:  (1, 4)\n",
      "Starting position:  (1, 3)\n",
      "Terminal State:  (2, 2)\n",
      "2.0\n",
      "(2, 3)\n",
      "Reward:  -1.0\n",
      "3.0\n",
      "(2, 2)\n",
      "Reward:  49.0\n",
      "Ending position:  (2, 2)\n",
      "Starting position:  (4, 4)\n",
      "Terminal State:  (2, 2)\n",
      "0.0\n",
      "(3, 4)\n",
      "Reward:  -1.0\n",
      "0.0\n",
      "(2, 4)\n",
      "Reward:  -2.0\n",
      "3.0\n",
      "(2, 3)\n",
      "Reward:  -3.0\n",
      "3.0\n",
      "(2, 2)\n",
      "Reward:  47.0\n",
      "Ending position:  (2, 2)\n",
      "Starting position:  (1, 0)\n",
      "Terminal State:  (0, 4)\n",
      "0.0\n",
      "(0, 0)\n",
      "Reward:  -1.0\n",
      "1.0\n",
      "(0, 1)\n",
      "Reward:  -2.0\n",
      "1.0\n",
      "(0, 2)\n",
      "Reward:  -3.0\n",
      "1.0\n",
      "(0, 3)\n",
      "Reward:  -4.0\n",
      "1.0\n",
      "(0, 4)\n",
      "Reward:  46.0\n",
      "Ending position:  (0, 4)\n",
      "Starting position:  (0, 4)\n",
      "Terminal State:  (4, 0)\n",
      "2.0\n",
      "(1, 4)\n",
      "Reward:  -1.0\n",
      "2.0\n",
      "(2, 4)\n",
      "Reward:  -2.0\n",
      "2.0\n",
      "(3, 4)\n",
      "Reward:  -3.0\n",
      "2.0\n",
      "(4, 4)\n",
      "Reward:  -4.0\n",
      "3.0\n",
      "(4, 3)\n",
      "Reward:  -5.0\n",
      "3.0\n",
      "(4, 2)\n",
      "Reward:  -6.0\n",
      "3.0\n",
      "(4, 1)\n",
      "Reward:  -7.0\n",
      "3.0\n",
      "(4, 0)\n",
      "Reward:  43.0\n",
      "Ending position:  (4, 0)\n",
      "Starting position:  (1, 4)\n",
      "Terminal State:  (3, 3)\n",
      "2.0\n",
      "(2, 4)\n",
      "Reward:  -1.0\n",
      "2.0\n",
      "(3, 4)\n",
      "Reward:  -2.0\n",
      "3.0\n",
      "(3, 3)\n",
      "Reward:  48.0\n",
      "Ending position:  (3, 3)\n",
      "Starting position:  (4, 2)\n",
      "Terminal State:  (1, 3)\n",
      "0.0\n",
      "(3, 2)\n",
      "Reward:  -1.0\n",
      "0.0\n",
      "(2, 2)\n",
      "Reward:  -2.0\n",
      "0.0\n",
      "(1, 2)\n",
      "Reward:  -3.0\n",
      "1.0\n",
      "(1, 3)\n",
      "Reward:  47.0\n",
      "Ending position:  (1, 3)\n",
      "Starting position:  (0, 2)\n",
      "Terminal State:  (3, 0)\n",
      "2.0\n",
      "(1, 2)\n",
      "Reward:  -1.0\n",
      "2.0\n",
      "(2, 2)\n",
      "Reward:  -2.0\n",
      "2.0\n",
      "(3, 2)\n",
      "Reward:  -3.0\n",
      "3.0\n",
      "(3, 1)\n",
      "Reward:  -4.0\n",
      "3.0\n",
      "(3, 0)\n",
      "Reward:  46.0\n",
      "Ending position:  (3, 0)\n"
     ]
    }
   ],
   "source": [
    "for episode in range(20):\n",
    "    done = False\n",
    "    reward_total = 0\n",
    "    iteration = 0\n",
    "\n",
    "    start_y = np.random.randint(low=0, high=env_y)\n",
    "    start_x = np.random.randint(low=0, high=env_x)\n",
    "    current_state = (start_y, start_x)\n",
    "\n",
    "    term_y = np.random.randint(low=0, high=env_y)\n",
    "    term_x = np.random.randint(low=0, high=env_x)\n",
    "    terminal_state_grid = (term_y, term_x)\n",
    "\n",
    "\n",
    "    BLACK = (0, 0, 0)\n",
    "    WHITE = (255, 255, 255)\n",
    "    GREEN = (0, 255, 0)\n",
    "    RED = (255, 0, 0)\n",
    "\n",
    "    pygame.init()\n",
    "\n",
    "    CONSTANT_SIZE = 50\n",
    "    height = env_state_space.shape[1]\n",
    "    width = env_state_space.shape[2]\n",
    "\n",
    "    size_y = (CONSTANT_SIZE * height) + height + 1\n",
    "    size_x = (CONSTANT_SIZE * width) + width + 1\n",
    "    screen_size = (size_y, size_x)\n",
    "\n",
    "    screen = pygame.display.set_mode(screen_size)\n",
    "\n",
    "    pygame.display.set_caption(\"Badworld\")\n",
    "\n",
    "    session = True\n",
    "\n",
    "    clock = pygame.time.Clock()\n",
    "\n",
    "    print(\"Starting position: \", current_state)\n",
    "    print(\"Terminal State: \", terminal_state_grid)\n",
    "\n",
    "    z = env_term_state.index(terminal_state_grid)\n",
    "\n",
    "    screen.fill(BLACK)\n",
    "\n",
    "    for y in range(height):\n",
    "        for x in range(width):                \n",
    "            if y == current_state[0] and x == current_state[1]:\n",
    "                colour = GREEN\n",
    "            elif env_state_space[z,y,x] == 50:\n",
    "                colour = RED\n",
    "            else:\n",
    "                colour = WHITE\n",
    "\n",
    "            rect_pos_x = x*(CONSTANT_SIZE+1)+1\n",
    "            rect_pos_y = y*(CONSTANT_SIZE+1)+1\n",
    "            rect = pygame.Rect(rect_pos_x, rect_pos_y , CONSTANT_SIZE, CONSTANT_SIZE)\n",
    "            pygame.draw.rect(screen, colour, rect) \n",
    "\n",
    "    pygame.display.flip()\n",
    "    pygame.time.wait(350)    \n",
    "\n",
    "    while session:\n",
    "\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                session = False\n",
    "\n",
    "        if done == True:\n",
    "            break\n",
    "\n",
    "        screen.fill(BLACK)\n",
    "\n",
    "        action = Pi[z,current_state[0],current_state[1]]\n",
    "        print(action)\n",
    "        obs, rew, done = step(current_state, action,z) \n",
    "        print(obs)\n",
    "        current_state = obs\n",
    "        reward_total += rew\n",
    "\n",
    "        for y in range(height):\n",
    "            for x in range(width):                \n",
    "                if y == current_state[0] and x == current_state[1]:\n",
    "                    colour = GREEN\n",
    "                elif env_state_space[z,y,x] == 50:\n",
    "                    colour = RED\n",
    "                else:\n",
    "                    colour = WHITE\n",
    "\n",
    "                rect_pos_x = x*(CONSTANT_SIZE+1)+1\n",
    "                rect_pos_y = y*(CONSTANT_SIZE+1)+1\n",
    "                rect = pygame.Rect(rect_pos_x, rect_pos_y , CONSTANT_SIZE, CONSTANT_SIZE)\n",
    "                pygame.draw.rect(screen, colour, rect)    \n",
    "\n",
    "        print(\"Reward: \" ,reward_total)\n",
    "\n",
    "        pygame.display.flip()\n",
    "        pygame.time.wait(350)\n",
    "        clock.tick(60)\n",
    "\n",
    "    #pygame.quit()\n",
    "\n",
    "    print(\"Ending position: \", current_state)\n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#texting dreams\n",
    "\n",
    "#font = pygame.font.Font('freesansbold.ttf', 10) \n",
    "#draw_text = True\n",
    "\n",
    "#if draw_text == True:\n",
    "#        text_pos_x = current_state[1]*(CONSTANT_SIZE+1)+1\n",
    "#        text_pos_y = current_state[0]*(CONSTANT_SIZE+1)+1\n",
    "#        rect = pygame.Rect(text_pos_x, text_pos_y , CONSTANT_SIZE, CONSTANT_SIZE)\n",
    "#        text_word = \"(\" +  str(current_state[0]) + \"; \" + str(current_state[1]) + \")\"\n",
    "#        text_pos_x = current_state[1]*(CONSTANT_SIZE+1)+1\n",
    "#        text_pos_y = current_state[0]*(CONSTANT_SIZE+1)+1\n",
    "#        text = font.render(text_word, True, BLACK, WHITE) \n",
    "#        textRect = text.get_rect()  \n",
    "#        textRect.center = (text_pos_x+(CONSTANT_SIZE/2), text_pos_y+(CONSTANT_SIZE/2)) \n",
    "#        screen.blit(text, textRect)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
